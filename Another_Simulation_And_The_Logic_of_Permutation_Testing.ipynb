{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e659410",
   "metadata": {},
   "source": [
    "# Another method of doing simulations\n",
    "\n",
    "We'll quickly look at a different method of doing the simulations you saw last session. This method is a bit trickier to think about than using strings like `CORRECT` or `INCORRECT`, but you might see it used in other peoples' code, so it is important to understand.\n",
    "\n",
    "Remember the scenario from the last session:\n",
    "\n",
    ">You have a friend who claims that through [extrasensory perception]>(https://en.wikipedia.org/wiki/Extrasensory_perception#:~:text=Extrasensory%20perception%20(ESP)%2C%20also,but%20sensed%20with%20the%20mind.) they have the power to predict which card will be drawn next from a deck of cards.\n",
    "\n",
    ">You'd like to test this claim, in an unbiased fashion.\n",
    "\n",
    ">You draw, one by one, twenty cards from a deck. On each draw, your friend makes a guess as to the card's identity (e.g. Ace of Spades; 3 of Clubs etc.) before seeing the card. You then show them the true identity of the card, and then put the card back in the deck before the next draw. You both record the number of cards they correctly guessed.\n",
    "\n",
    ">Your friend guesses 8 of the 20 cards correctly.\n",
    "\n",
    ">Is that result surprising? Is your friend guessing randomly, or is there evidence they have some extrasensory ability e.g. the ability to \"perceive\" what the card is, in a non-random way?\n",
    "\n",
    ">If you friend does *not* have such an ability, then the chance of correctly guessing on each draw is $\\frac{1}{52}$, as there are 52 cards in a standard deck.\n",
    "\n",
    "Remember that our simulation model is that your friend's guesses are random? (E.g. we are in the Null World, where your friend does not have extrasensory abilities).\n",
    "\n",
    "That is, for any guess your friend has a $\\frac{1}{52}$ probability of being correct.\n",
    "\n",
    "Here is another way of doing the simulation - a bit more complex than the ones we saw last time, but important to understand. It involves simulating the guesses by taking 20 random numbers between 0 and 1. We then check if each number is lower than $\\frac{1}{52}$, and we take a `True` to mean a correct guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be832f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up the random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record how many guesses our friend made\n",
    "number_of_guesses = 20\n",
    "\n",
    "number_of_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa111102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the proportion of guesses our friend got correct\n",
    "proportion_of_correct_guesses = 8/number_of_guesses\n",
    "proportion_of_correct_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate 20 random guesses\n",
    "random_guesses = rng.uniform(0, 1, size=number_of_guesses)\n",
    "random_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of simulated correct guesses\n",
    "simulated_correct_guesses = np.count_nonzero(random_guesses < 1/52)\n",
    "simulated_correct_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758dad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use the following to count the number of correct guesses\n",
    "sum(random_guesses < 1/52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40326ae3",
   "metadata": {},
   "source": [
    "We stored your friend's correct guesses as a proportion e.g. $\\frac{1}{52}$. We can get the proportion of correct simulated guesses this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb808bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get the proportion/percentage of correct guesses by doing the following\n",
    "prop_simulated_correct_guesses = simulated_correct_guesses/number_of_guesses\n",
    "prop_simulated_correct_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228391b",
   "metadata": {},
   "source": [
    "Now, let's practice using this method to perform a simulation with 10_000 trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67264756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform your simulation here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f8feb",
   "metadata": {},
   "source": [
    "This rest of this notebook will re-vist your **permutation testing** skills (as well as your `pandas` skills). We use permutation testing (as opposed to simulation) when our observed statistic is a *difference between two groups*. Remember, we use simulation when testing a single sample, as we saw in the last session.\n",
    "\n",
    "Just FYI - there are other contexts we can use permutation testing, but the *between groups* context is the primary one you've seen. \n",
    "\n",
    "# Does a treatment work?\n",
    "\n",
    "Let's consider the following situation:\n",
    "\n",
    "- there is a disease with unpleasant symptoms\n",
    "- a pharmaceutical company rep tells you they have a drug treatment that can reduce the symptom severity (e.g. make people feel better)\n",
    "- they have conducted a study involving participants who have the disease. Participants were randomly assigned to the placebo group (where they received a fake treatment) and to the treatment group (where they received the drug)\n",
    "- the pharmaceutical company rep says there that the drug group has lower symptom severity, at the end of the study\n",
    "\n",
    "Let's have a look at the data and see if we should believe the pharmaceutical rep taht the drug is effective at reducing symptom severity...\n",
    "\n",
    "**Note**: the data is real experimental data, but the meaning has been changed (for increased clarity; the actual data is from [this dataset](https://github.com/lisds/textbook/blob/main/data/mosquito_beer.csv)).\n",
    "\n",
    "Here is the meaning of each column:\n",
    "\n",
    "- `participant_ID`: a unique identifier for each participant\n",
    "- `group`: whether the participant was in the `placebo` or `drug` group\n",
    "- `symptom_severity`: the symptom severity score of the the participant, at the end of the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d983389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "df = pd.read_csv(\"data/drug_placebo.csv\")\n",
    "         \n",
    "df         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119916e",
   "metadata": {},
   "source": [
    "Before we start to look at the data, let's clean it. You'll notice there is a \"junk\" first column. Let's remove that in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72866fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data by removing the first column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e3e2d",
   "metadata": {},
   "source": [
    "The first thing we want to check, is whether the average symptom severity between the two groups is different, as the pharmaceutical company rep says.\n",
    "\n",
    "The code cells below describe the process for doing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0d4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the data for the placebo group, in a variable called `placebo_group`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the data for the drug group, in a variable called `drug_group`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4caa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean of the placebo group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3850e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean of the drug group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the difference between the means (let's discuss which direction of subtraction makes the most sense,\n",
    "# either is fine, but one may be easier to interpret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec8ad3",
   "metadata": {},
   "source": [
    "Let's plot the data. We're going to want to plot each group separately (e.g. to see if there is a difference between the two groups).\n",
    "\n",
    "You may also consider using `plt.axvline()` to plot the group means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a5ac9d",
   "metadata": {},
   "source": [
    "Are you convinced by the difference in means - is the treatment effective? Let's discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c0cb3",
   "metadata": {},
   "source": [
    "### The Logic of Permutation Testing\n",
    "\n",
    "Let's imagine a skeptic arguing with the pharmaceutical company rep. The skeptic refuses to accept that the difference in means indicates that the treatment works.\n",
    "\n",
    "The skeptic's argument is that the difference we see is just a quirk in this sample - the difference is not big enough to convince us that the drug would work if we gave it to other people with the disease outside of this sample. E.g. if we gave it to others from the *population* of people who suffer with the disease.\n",
    "\n",
    "Let's think about what the skeptic is saying here, they are saying that the treatment makes **no difference**. One way of thinking of what the skeptic is saying is this:\n",
    "\n",
    "- we have only one sample from the population of all people with the disease\n",
    "- if we had gotten a different sample, we would have observed no difference in the syptom severity scores, because the drug is ineffective\n",
    "- it merely happens that through random chance we got a sample where we observe a difference **but we would not observe thsi difference consistently if we repeated the study with new samples from the same population**\n",
    "\n",
    "The logic of permutation testing is built on this skeptical claim. If the treatment makes no difference, then the group identification labels `placebo` and `drug` should be **exchangable** between the groups.\n",
    "\n",
    "By shuffling the group labels, we can simulate *drawing a new random sample under the assumption that the treatment is ineffective*. \n",
    "\n",
    "The skeptic is saying that The Null World - where the treatment does not work - is a good model of the real world. Permutation testing let's us simulate the Null World by shuffling the group labels, thus removing any association between the treatment and the symptom severity scores.\n",
    "\n",
    "If we shuffle a large number of times - and recalculate the difference in average symptom severity score each time - we can then build a distribution of the sorts of differences we would expect if the treatment is ineffective. \n",
    "\n",
    "Let's do this in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe49137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the permutation test here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a68ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results of the permutation test here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5888210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate your p-value here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f5386f",
   "metadata": {},
   "source": [
    "# Political views \n",
    "\n",
    "The last permutation test we did involved testing for a difference between groups using a numerical score (`symptom_severity`).\n",
    "\n",
    "However, you will encounter other types of data, for which you can use a permutation test.\n",
    "\n",
    "Let's look at the following data on abortion views and political party affiliation (again, this is based on real data, but the meaning has been changed e.g. the original data was not about abortion views).\n",
    "\n",
    "Let's assume the data is a random sample from a small town.\n",
    "\n",
    "We want to know if being `republican` or being `democrat` have the same (or different) association with being `pro_abortion`.\n",
    "\n",
    "The Null World would be a world where *there is no difference in the proportion of republicans who are pro-abortion relative to the proportion of democrats who are pro abortion*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384611f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "df2 = pd.read_csv('data/abortion_views_rep_dem.csv')\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataframe easier to index\n",
    "df2.set_index(\"pro_abortion\", inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of republcian Yes's in its own variable\n",
    "n_yes_republican = df2.loc['Yes', 'republican']\n",
    "n_yes_republican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of republcian No's in its own variable\n",
    "n_no_republican = df2.loc['No', 'republican']\n",
    "n_no_republican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total number of republicans\n",
    "n_republican = df2.loc['out of', 'republican']\n",
    "n_republican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of democrat Yes's\n",
    "n_yes_democrat = df2.loc['Yes', 'democrat']\n",
    "n_yes_democrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194463f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of democrat No's\n",
    "n_no_democrat = df2.loc['No', 'democrat']\n",
    "n_no_democrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total number of democrts\n",
    "n_democrat = df2.loc['out of', 'democrat']\n",
    "n_democrat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025a7bbc",
   "metadata": {},
   "source": [
    "We can now calculate the difference in proprtions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253762c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_yes_democrat/n_democrat - n_yes_republican/n_republican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ac636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3729de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same calculation using numbers straight from the table\n",
    "54/66 - 64/249 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d066cf0",
   "metadata": {},
   "source": [
    "Now, you'll notice there's not much for us to shuffle in this data!\n",
    "\n",
    "That's because the data is *aggregated* - e.g. it is a count of the number of people with specific characteristics (e.g. being `republican` or `democrat`, or being pro abortion or not.\n",
    "\n",
    "In order to perform a permutation test here - e.g. to simulate the null world where there is no difference in the proportion of republicans who are pro-abortion relative to the proportion of democrats who are pro-abortion - we need to recreate the raw data.\n",
    "\n",
    "**The raw data is a dataframe with one row for each person counted in the original dataframe.**\n",
    "\n",
    "The function `np.repeat()` is very useful here, for recreating the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a useful function to use here, for recreating the raw data\n",
    "np.repeat('republican', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the labels for the republicans\n",
    "republican_labels = np.repeat('republican', n_republican)\n",
    "yes_republican = np.repeat('Yes', n_yes_republican)\n",
    "no_republican = np.repeat('No', n_no_republican)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c060f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stick the republican yes's and no's together\n",
    "republican_yes_no = np.append(yes_republican, no_republican)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for the republican data\n",
    "republican_df = pd.DataFrame()\n",
    "republican_df['political_party'] = republican_labels\n",
    "republican_df['pro_abortion'] = republican_yes_no\n",
    "\n",
    "republican_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b03bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the labels for the democrats\n",
    "democrat_labels = np.repeat('democrat', n_democrat)\n",
    "yes_democrat = np.repeat('Yes', n_yes_democrat)\n",
    "no_democrat = np.repeat('No', n_no_democrat)\n",
    "democrat_yes_no = np.append(yes_democrat, no_democrat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for the democrats\n",
    "democrat_df = pd.DataFrame()\n",
    "democrat_df['political_party'] = democrat_labels\n",
    "democrat_df['pro_abortion'] =democrat_yes_no\n",
    "\n",
    "democrat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db973f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the raw data dataframe\n",
    "raw_data = pd.concat([republican_df, democrat_df])\n",
    "\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f728a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the raw data corresponds to the original data\n",
    "pd.crosstab(raw_data['pro_abortion'], raw_data['political_party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b5cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the original data for comparison\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401dae1",
   "metadata": {},
   "source": [
    "We can now shuffle the raw data to generate a simulated table of counts - this simulates taking a new sample from the Null World, where there is no association between party membership and abortion views:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a simulated table \n",
    "simulated_counts = pd.crosstab(np.random.permutation(raw_data['pro_abortion']), raw_data['political_party'])\n",
    "simulated_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1501f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated statistic\n",
    "simulated_counts.loc['Yes', 'democrat']/simulated_counts['democrat'].sum() -  simulated_counts.loc['Yes', 'republican']/simulated_counts['republican'].sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2e07e",
   "metadata": {},
   "source": [
    "We can now perform a permutation test by shuffling the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do you permutation test here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0199a1e",
   "metadata": {},
   "source": [
    "# More political views\n",
    "\n",
    "You can practice the same test using the data below, e.g. testing whether being `democrat` or being `independent` have the same (or different) association with being `pro_abortion`:\n",
    "\n",
    "*Note*: please feel free to send me some screenshots via teams of your code and simulation - I am happy to informally mark your code this way :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a583fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the democrat/independent data\n",
    "df3 = pd.read_csv('data/abortion_views_dem_ind.csv')\n",
    "                  \n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"explode\" your data to the raw data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform your simulation test here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
